{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-12-30T07:22:09.173346900Z",
     "start_time": "2023-12-30T07:17:29.146909100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1 Train - Loss: 0.6914006471633911, - AUC: 0.8981957315609842 - AUPR: 0.8901212704164303\n",
      "Epoch:2 Train - Loss: 0.6888253688812256, - AUC: 0.8724738921734251 - AUPR: 0.857275021890657\n",
      "Epoch:3 Train - Loss: 0.6693514585494995, - AUC: 0.9211063074522916 - AUPR: 0.9210189301539611\n",
      "Epoch:4 Train - Loss: 0.6271985769271851, - AUC: 0.9158867124649627 - AUPR: 0.9122464799441699\n",
      "Epoch:5 Train - Loss: 0.5837936401367188, - AUC: 0.9131030335558621 - AUPR: 0.9117207717359808\n",
      "Epoch:6 Train - Loss: 0.5589980483055115, - AUC: 0.9086047755225407 - AUPR: 0.9083291214824418\n",
      "Epoch:7 Train - Loss: 0.532586395740509, - AUC: 0.9095643250898765 - AUPR: 0.9055980241259644\n",
      "Epoch:8 Train - Loss: 0.49660295248031616, - AUC: 0.9103171872863426 - AUPR: 0.9062094546955803\n",
      "Epoch:9 Train - Loss: 0.47924256324768066, - AUC: 0.9099737591763084 - AUPR: 0.9085686662678387\n",
      "Epoch:10 Train - Loss: 0.45704787969589233, - AUC: 0.9100703052313381 - AUPR: 0.9048413491090098\n",
      "Epoch:11 Train - Loss: 0.4171416163444519, - AUC: 0.9100155301225662 - AUPR: 0.9041215247266153\n",
      "Epoch:12 Train - Loss: 0.4272359311580658, - AUC: 0.9080593888280057 - AUPR: 0.897309112052488\n",
      "Epoch:13 Train - Loss: 0.3925778269767761, - AUC: 0.9113281624054391 - AUPR: 0.8955988831481222\n",
      "Epoch:14 Train - Loss: 0.3817959725856781, - AUC: 0.9233710020574161 - AUPR: 0.9038528539502702\n",
      "Epoch:15 Train - Loss: 0.3712017834186554, - AUC: 0.9286430077603323 - AUPR: 0.9076289538932911\n",
      "Epoch:16 Train - Loss: 0.3569026291370392, - AUC: 0.9283332722531761 - AUPR: 0.9062333079200091\n",
      "Epoch:17 Train - Loss: 0.34811288118362427, - AUC: 0.9287239882268982 - AUPR: 0.9046662146220766\n",
      "Epoch:18 Train - Loss: 0.33904048800468445, - AUC: 0.9313005856995984 - AUPR: 0.9103845027939372\n",
      "Epoch:19 Train - Loss: 0.3350324332714081, - AUC: 0.9332131827530129 - AUPR: 0.9109530522774979\n",
      "Epoch:20 Train - Loss: 0.330380916595459, - AUC: 0.934146132897024 - AUPR: 0.9092454415312536\n",
      "Epoch:21 Train - Loss: 0.32454171776771545, - AUC: 0.9350339625377663 - AUPR: 0.9107028742832104\n",
      "Epoch:22 Train - Loss: 0.3249661922454834, - AUC: 0.9330476752301047 - AUPR: 0.9091864215265205\n",
      "Epoch:23 Train - Loss: 0.3304583728313446, - AUC: 0.930831844750791 - AUPR: 0.9052633346333595\n",
      "Epoch:24 Train - Loss: 0.3411179780960083, - AUC: 0.926713662921862 - AUPR: 0.9041233138040186\n",
      "Epoch:25 Train - Loss: 0.34051039814949036, - AUC: 0.9307418007770185 - AUPR: 0.904816041090749\n",
      "Epoch:26 Train - Loss: 0.31672748923301697, - AUC: 0.931909811010112 - AUPR: 0.9085801078528328\n",
      "Epoch:27 Train - Loss: 0.3320330083370209, - AUC: 0.9327369545591215 - AUPR: 0.91034094733238\n",
      "Epoch:28 Train - Loss: 0.31209519505500793, - AUC: 0.9341932237279466 - AUPR: 0.9114063910492239\n",
      "Epoch:29 Train - Loss: 0.3226470947265625, - AUC: 0.9336831058984123 - AUPR: 0.9101907896205907\n",
      "Epoch:30 Train - Loss: 0.31265726685523987, - AUC: 0.934156378600823 - AUPR: 0.9114518857933444\n",
      "Epoch:31 Train - Loss: 0.31600531935691833, - AUC: 0.9345794079480652 - AUPR: 0.9130576456565554\n",
      "Epoch:32 Train - Loss: 0.3102104961872101, - AUC: 0.9356857469255992 - AUPR: 0.9149163239614064\n",
      "Epoch:33 Train - Loss: 0.30676716566085815, - AUC: 0.9372600387208789 - AUPR: 0.9168689570003097\n",
      "Epoch:34 Train - Loss: 0.3085024356842041, - AUC: 0.9378988189461978 - AUPR: 0.9183685691234923\n",
      "Epoch:35 Train - Loss: 0.30820998549461365, - AUC: 0.9373408221546794 - AUPR: 0.9198546341923818\n",
      "Epoch:36 Train - Loss: 0.3057059347629547, - AUC: 0.9380513223065916 - AUPR: 0.920585219537342\n",
      "Epoch:37 Train - Loss: 0.3014703094959259, - AUC: 0.9388851649696235 - AUPR: 0.9197504866245145\n",
      "Epoch:38 Train - Loss: 0.3002268075942993, - AUC: 0.9388363008438125 - AUPR: 0.9196012219227706\n",
      "Epoch:39 Train - Loss: 0.2993921637535095, - AUC: 0.9389354083247919 - AUPR: 0.9198332775732543\n",
      "Epoch:40 Train - Loss: 0.29724255204200745, - AUC: 0.9394407973679575 - AUPR: 0.9200927646712888\n",
      "Epoch:41 Train - Loss: 0.29663553833961487, - AUC: 0.9393395225265591 - AUPR: 0.9189063385649013\n",
      "Epoch:42 Train - Loss: 0.294268935918808, - AUC: 0.9398226468672382 - AUPR: 0.9199863598603857\n",
      "Epoch:43 Train - Loss: 0.2937788963317871, - AUC: 0.9400618446443934 - AUPR: 0.9210598171928859\n",
      "Epoch:44 Train - Loss: 0.2942611575126648, - AUC: 0.940426552293087 - AUPR: 0.9213075925266251\n",
      "Epoch:45 Train - Loss: 0.2920656204223633, - AUC: 0.9401631194857919 - AUPR: 0.920227960148061\n",
      "Epoch:46 Train - Loss: 0.2919914722442627, - AUC: 0.9401229248016569 - AUPR: 0.9206160625312543\n",
      "Epoch:47 Train - Loss: 0.2924843430519104, - AUC: 0.9408267258395467 - AUPR: 0.9219251578322767\n",
      "Epoch:48 Train - Loss: 0.2884657084941864, - AUC: 0.9412306430085485 - AUPR: 0.9224016555646797\n",
      "Epoch:49 Train - Loss: 0.29085686802864075, - AUC: 0.9413433457503382 - AUPR: 0.9226504002511681\n",
      "Epoch:50 Train - Loss: 0.29178833961486816, - AUC: 0.9419703040097349 - AUPR: 0.9230765301391305\n",
      "Epoch:51 Train - Loss: 0.2852448523044586, - AUC: 0.9420709877528374 - AUPR: 0.9232466951651597\n",
      "Epoch:52 Train - Loss: 0.2935914695262909, - AUC: 0.9416148569010137 - AUPR: 0.9227707796832632\n",
      "Epoch:53 Train - Loss: 0.2911030650138855, - AUC: 0.9412584246284652 - AUPR: 0.9217850983744809\n",
      "Epoch:54 Train - Loss: 0.2929103970527649, - AUC: 0.9412661089063145 - AUPR: 0.9218220271910156\n",
      "Epoch:55 Train - Loss: 0.28738197684288025, - AUC: 0.9423580644919766 - AUPR: 0.9239274748511969\n",
      "Epoch:56 Train - Loss: 0.2915300130844116, - AUC: 0.9430683676111236 - AUPR: 0.9244898525623739\n",
      "Epoch:57 Train - Loss: 0.283863365650177, - AUC: 0.9434115986883922 - AUPR: 0.9238352574664122\n",
      "Epoch:58 Train - Loss: 0.28414252400398254, - AUC: 0.9434110075900962 - AUPR: 0.922908287783423\n",
      "Epoch:59 Train - Loss: 0.2788839042186737, - AUC: 0.9437049804760234 - AUPR: 0.9243139237479296\n",
      "Epoch:60 Train - Loss: 0.28227031230926514, - AUC: 0.9427745917579619 - AUPR: 0.9237985894240021\n",
      "Epoch:61 Train - Loss: 0.2774714529514313, - AUC: 0.9431505302742813 - AUPR: 0.9236761236383582\n",
      "Epoch:62 Train - Loss: 0.27681633830070496, - AUC: 0.9447291567903994 - AUPR: 0.9255901017767598\n",
      "Epoch:63 Train - Loss: 0.2727755308151245, - AUC: 0.9450991843237578 - AUPR: 0.9267123099406681\n",
      "Epoch:64 Train - Loss: 0.2738218605518341, - AUC: 0.9452422301114141 - AUPR: 0.9271262588075588\n",
      "Epoch:65 Train - Loss: 0.26966550946235657, - AUC: 0.9460388335817917 - AUPR: 0.927559034173014\n",
      "Epoch:66 Train - Loss: 0.2702518701553345, - AUC: 0.9468035177441797 - AUPR: 0.9275051886253439\n",
      "Epoch:67 Train - Loss: 0.26676371693611145, - AUC: 0.9471597529839627 - AUPR: 0.9295744958944476\n",
      "Epoch:68 Train - Loss: 0.2665805518627167, - AUC: 0.9471317743312806 - AUPR: 0.92961369152354\n",
      "Epoch:69 Train - Loss: 0.2622990310192108, - AUC: 0.9482312171620267 - AUPR: 0.9294595718105972\n",
      "Epoch:70 Train - Loss: 0.2604967951774597, - AUC: 0.9480724087531412 - AUPR: 0.9292243241387533\n",
      "Epoch:71 Train - Loss: 0.2586003541946411, - AUC: 0.9486248886272293 - AUPR: 0.9297080034638228\n",
      "Epoch:72 Train - Loss: 0.2567853331565857, - AUC: 0.9486426215761125 - AUPR: 0.9298929527381788\n",
      "Epoch:73 Train - Loss: 0.25538069009780884, - AUC: 0.9487923664777911 - AUPR: 0.9298344001769764\n",
      "Epoch:74 Train - Loss: 0.25303444266319275, - AUC: 0.9501723839664192 - AUPR: 0.9307652613957286\n",
      "Epoch:75 Train - Loss: 0.2530042231082916, - AUC: 0.9496963528052934 - AUPR: 0.9302137984775412\n",
      "Epoch:76 Train - Loss: 0.25133323669433594, - AUC: 0.9510286883647029 - AUPR: 0.9317155034689544\n",
      "Epoch:77 Train - Loss: 0.2538273334503174, - AUC: 0.9494082909023274 - AUPR: 0.9298243674687746\n",
      "Epoch:78 Train - Loss: 0.2531222105026245, - AUC: 0.9512860131562717 - AUPR: 0.9316863294981277\n",
      "Epoch:79 Train - Loss: 0.2471836507320404, - AUC: 0.9513801948181171 - AUPR: 0.9321620725860819\n",
      "Epoch:80 Train - Loss: 0.24803948402404785, - AUC: 0.9505589622520687 - AUPR: 0.9322856223648432\n",
      "Epoch:81 Train - Loss: 0.2529899477958679, - AUC: 0.9520950296908675 - AUPR: 0.9344754666527735\n",
      "Epoch:82 Train - Loss: 0.24341155588626862, - AUC: 0.9520599578586322 - AUPR: 0.9344885255337059\n",
      "Epoch:83 Train - Loss: 0.24210742115974426, - AUC: 0.9524252566056219 - AUPR: 0.9343374879074157\n",
      "Epoch:84 Train - Loss: 0.24581395089626312, - AUC: 0.952691250838867 - AUPR: 0.9347673365403426\n",
      "Epoch:85 Train - Loss: 0.24325084686279297, - AUC: 0.9523503841547827 - AUPR: 0.934315984646709\n",
      "Epoch:86 Train - Loss: 0.24239343404769897, - AUC: 0.9517805653973421 - AUPR: 0.9338805637537214\n",
      "Epoch:87 Train - Loss: 0.24701057374477386, - AUC: 0.9541741194310167 - AUPR: 0.9371686258726881\n",
      "Epoch:88 Train - Loss: 0.2451658844947815, - AUC: 0.9551703170927105 - AUPR: 0.9388533943699918\n",
      "Epoch:89 Train - Loss: 0.26117897033691406, - AUC: 0.9469497160560818 - AUPR: 0.9308152991345648\n",
      "Epoch:90 Train - Loss: 0.27790796756744385, - AUC: 0.9505818180528512 - AUPR: 0.9367215515570139\n",
      "Epoch:91 Train - Loss: 0.27243325114250183, - AUC: 0.9480452182315205 - AUPR: 0.933776327072189\n",
      "Epoch:92 Train - Loss: 0.26818642020225525, - AUC: 0.9498232419061894 - AUPR: 0.9345611247565622\n",
      "Epoch:93 Train - Loss: 0.26679083704948425, - AUC: 0.9513074897276967 - AUPR: 0.9362898006778657\n",
      "Epoch:94 Train - Loss: 0.24996313452720642, - AUC: 0.9516714092453291 - AUPR: 0.9375793612415809\n",
      "Epoch:95 Train - Loss: 0.261568158864975, - AUC: 0.9513187205953226 - AUPR: 0.9354675688743338\n",
      "Epoch:96 Train - Loss: 0.25395819544792175, - AUC: 0.9514590079242639 - AUPR: 0.9354463501128013\n",
      "Epoch:97 Train - Loss: 0.257777601480484, - AUC: 0.948918073382095 - AUPR: 0.933556396596363\n",
      "Epoch:98 Train - Loss: 0.24117936193943024, - AUC: 0.9540925478661547 - AUPR: 0.9396145397880253\n",
      "Epoch:99 Train - Loss: 0.2411796599626541, - AUC: 0.9549884558502773 - AUPR: 0.9394784929496149\n",
      "Epoch:100 Train - Loss: 0.24075230956077576, - AUC: 0.9542777586655995 - AUPR: 0.9365490847779445\n",
      "Epoch:101 Train - Loss: 0.24382248520851135, - AUC: 0.9513266019059373 - AUPR: 0.9331386018750137\n",
      "Epoch:102 Train - Loss: 0.23471631109714508, - AUC: 0.9560642547491792 - AUPR: 0.9385024869084947\n",
      "Epoch:103 Train - Loss: 0.23620623350143433, - AUC: 0.9562800056272557 - AUPR: 0.9389157488792707\n",
      "Epoch:104 Train - Loss: 0.23236262798309326, - AUC: 0.9548909246314207 - AUPR: 0.9377109848608737\n",
      "Epoch:105 Train - Loss: 0.23178112506866455, - AUC: 0.9547888616589608 - AUPR: 0.9374635702729464\n",
      "Epoch:106 Train - Loss: 0.22588057816028595, - AUC: 0.9584879547959549 - AUPR: 0.9405614088719875\n",
      "Epoch:107 Train - Loss: 0.23004277050495148, - AUC: 0.9575674177161616 - AUPR: 0.9400558464016473\n",
      "Epoch:108 Train - Loss: 0.2259792685508728, - AUC: 0.9588662577054589 - AUPR: 0.9412208609056933\n",
      "Epoch:109 Train - Loss: 0.22815731167793274, - AUC: 0.9578211959179539 - AUPR: 0.9408397775426642\n",
      "Epoch:110 Train - Loss: 0.22474323213100433, - AUC: 0.9567907145550864 - AUPR: 0.9393439110855859\n",
      "Epoch:111 Train - Loss: 0.22882601618766785, - AUC: 0.9585785898680235 - AUPR: 0.94149154764428\n",
      "Epoch:112 Train - Loss: 0.22028061747550964, - AUC: 0.9607380689764424 - AUPR: 0.9430936353331709\n",
      "Epoch:113 Train - Loss: 0.22269493341445923, - AUC: 0.9583744639231037 - AUPR: 0.9408006506350741\n",
      "Epoch:114 Train - Loss: 0.2190091758966446, - AUC: 0.9622236960273072 - AUPR: 0.9449220078921747\n",
      "Epoch:115 Train - Loss: 0.2199890911579132, - AUC: 0.9609449533800773 - AUPR: 0.9440721346780435\n",
      "Epoch:116 Train - Loss: 0.2182316780090332, - AUC: 0.9597578309687431 - AUPR: 0.9428110199128291\n",
      "Epoch:117 Train - Loss: 0.21295131742954254, - AUC: 0.9613088728977097 - AUPR: 0.9424943417430436\n",
      "Epoch:118 Train - Loss: 0.21780557930469513, - AUC: 0.9632679696837505 - AUPR: 0.946790362545928\n",
      "Epoch:119 Train - Loss: 0.2121090292930603, - AUC: 0.9643410101239376 - AUPR: 0.9476531874983019\n",
      "Epoch:120 Train - Loss: 0.21947886049747467, - AUC: 0.9596859140093843 - AUPR: 0.9441750190908309\n",
      "Epoch:121 Train - Loss: 0.22067910432815552, - AUC: 0.9627663242631271 - AUPR: 0.9471168715265437\n",
      "Epoch:122 Train - Loss: 0.21325629949569702, - AUC: 0.9649520087293397 - AUPR: 0.9482485607199755\n",
      "Epoch:123 Train - Loss: 0.20887762308120728, - AUC: 0.9644064250020392 - AUPR: 0.9493982279892741\n",
      "Epoch:124 Train - Loss: 0.2257615476846695, - AUC: 0.9572568940779438 - AUPR: 0.9407125499754843\n",
      "Epoch:125 Train - Loss: 0.2267012894153595, - AUC: 0.9619439095004865 - AUPR: 0.9457019147963492\n",
      "Epoch:126 Train - Loss: 0.2478512078523636, - AUC: 0.9559091899628357 - AUPR: 0.940310861351633\n",
      "Epoch:127 Train - Loss: 0.23954622447490692, - AUC: 0.9588871431785877 - AUPR: 0.9428790241996703\n",
      "Epoch:128 Train - Loss: 0.21845948696136475, - AUC: 0.9650879613374426 - AUPR: 0.9474023733914887\n",
      "Epoch:129 Train - Loss: 0.2102935016155243, - AUC: 0.9632462960795601 - AUPR: 0.9465367669033776\n",
      "Epoch:130 Train - Loss: 0.21846909821033478, - AUC: 0.9600326916764297 - AUPR: 0.9441913971094308\n",
      "Epoch:131 Train - Loss: 0.21691714227199554, - AUC: 0.9672031080736541 - AUPR: 0.9527008591281347\n",
      "Epoch:132 Train - Loss: 0.21634022891521454, - AUC: 0.9653951354186492 - AUPR: 0.9503386907482705\n",
      "Epoch:133 Train - Loss: 0.22112274169921875, - AUC: 0.9663444392821859 - AUPR: 0.9512502473514879\n",
      "Epoch:134 Train - Loss: 0.20364373922348022, - AUC: 0.9698149744113547 - AUPR: 0.9574641699246218\n",
      "Epoch:135 Train - Loss: 0.20867827534675598, - AUC: 0.9624372795449647 - AUPR: 0.9486145243601367\n",
      "Epoch:136 Train - Loss: 0.20295001566410065, - AUC: 0.9685421427470859 - AUPR: 0.9554313758080768\n",
      "Epoch:137 Train - Loss: 0.20445138216018677, - AUC: 0.9689265536723163 - AUPR: 0.9557514327257974\n",
      "Epoch:138 Train - Loss: 0.19668875634670258, - AUC: 0.9703308061910848 - AUPR: 0.9574665313113446\n",
      "Epoch:139 Train - Loss: 0.20808057487010956, - AUC: 0.9698819655515794 - AUPR: 0.9577241507543789\n",
      "Epoch:140 Train - Loss: 0.194584459066391, - AUC: 0.9705522710193568 - AUPR: 0.9589967928332982\n",
      "Epoch:141 Train - Loss: 0.19347527623176575, - AUC: 0.9713238513285328 - AUPR: 0.9616128762506242\n",
      "Epoch:142 Train - Loss: 0.19812321662902832, - AUC: 0.9716789043717237 - AUPR: 0.962486982757191\n",
      "Epoch:143 Train - Loss: 0.19102762639522552, - AUC: 0.9718144629142959 - AUPR: 0.9620824744201957\n",
      "Epoch:144 Train - Loss: 0.19029563665390015, - AUC: 0.9737097210843579 - AUPR: 0.9658620462020817\n",
      "Epoch:145 Train - Loss: 0.1857752948999405, - AUC: 0.9760951967746525 - AUPR: 0.96943082933812\n",
      "Epoch:146 Train - Loss: 0.18334786593914032, - AUC: 0.9750938762610589 - AUPR: 0.9684045175540215\n",
      "Epoch:147 Train - Loss: 0.1848413050174713, - AUC: 0.9729020837791201 - AUPR: 0.9660660917133889\n",
      "Epoch:148 Train - Loss: 0.1846356987953186, - AUC: 0.973177141519572 - AUPR: 0.9656396691266389\n",
      "Epoch:149 Train - Loss: 0.18397054076194763, - AUC: 0.9724110781278262 - AUPR: 0.9635622687983257\n",
      "Epoch:150 Train - Loss: 0.17884905636310577, - AUC: 0.9740665474224371 - AUPR: 0.9657555016709986\n",
      "Epoch:151 Train - Loss: 0.1770101934671402, - AUC: 0.9761365736553795 - AUPR: 0.9698583027567819\n",
      "Epoch:152 Train - Loss: 0.17993547022342682, - AUC: 0.9758150161823009 - AUPR: 0.9698846501080456\n",
      "Epoch:153 Train - Loss: 0.17328572273254395, - AUC: 0.9769924839881323 - AUPR: 0.9714022257153732\n",
      "Epoch:154 Train - Loss: 0.1753048449754715, - AUC: 0.9756554196423541 - AUPR: 0.9692689935613674\n",
      "Epoch:155 Train - Loss: 0.16982302069664001, - AUC: 0.9780115374506089 - AUPR: 0.9721159169271464\n",
      "Epoch:156 Train - Loss: 0.1739141047000885, - AUC: 0.976919187799416 - AUPR: 0.9705556035050374\n",
      "Epoch:157 Train - Loss: 0.16666646301746368, - AUC: 0.9780462152173134 - AUPR: 0.9711412340734418\n",
      "Epoch:158 Train - Loss: 0.18284012377262115, - AUC: 0.9739254719624345 - AUPR: 0.9668800154335635\n",
      "Epoch:159 Train - Loss: 0.19486850500106812, - AUC: 0.9710239674596447 - AUPR: 0.9640043682467068\n",
      "Epoch:160 Train - Loss: 0.2013695389032364, - AUC: 0.9689476361782107 - AUPR: 0.9613453629935655\n",
      "Epoch:161 Train - Loss: 0.2066812664270401, - AUC: 0.966230554343804 - AUPR: 0.9562137734558201\n",
      "Epoch:162 Train - Loss: 0.19788722693920135, - AUC: 0.9694953872659301 - AUPR: 0.9606520630869416\n",
      "Epoch:163 Train - Loss: 0.19840779900550842, - AUC: 0.9697724153340355 - AUPR: 0.960824117903693\n",
      "Epoch:164 Train - Loss: 0.1988622099161148, - AUC: 0.9681699478533083 - AUPR: 0.9570769167627746\n",
      "Epoch:165 Train - Loss: 0.19614900648593903, - AUC: 0.9690812243931293 - AUPR: 0.9582198405154229\n",
      "Epoch:166 Train - Loss: 0.19444209337234497, - AUC: 0.9700845152343763 - AUPR: 0.9603563000825501\n",
      "Epoch:167 Train - Loss: 0.19742579758167267, - AUC: 0.9705215339079596 - AUPR: 0.962774863935139\n",
      "Epoch:168 Train - Loss: 0.19511912763118744, - AUC: 0.9697401019605154 - AUPR: 0.9614174717939936\n",
      "Epoch:169 Train - Loss: 0.20634573698043823, - AUC: 0.9674202381810881 - AUPR: 0.9593293215470124\n",
      "Epoch:170 Train - Loss: 0.20521387457847595, - AUC: 0.9677733208966252 - AUPR: 0.9600235809909387\n",
      "Epoch:171 Train - Loss: 0.18937993049621582, - AUC: 0.9716264936561361 - AUPR: 0.9629212413953314\n",
      "Epoch:172 Train - Loss: 0.21558034420013428, - AUC: 0.9614229548688571 - AUPR: 0.9460083104698264\n",
      "Epoch:173 Train - Loss: 0.22604134678840637, - AUC: 0.962040849621047 - AUPR: 0.9484925335829365\n",
      "Epoch:174 Train - Loss: 0.23824532330036163, - AUC: 0.9567796807202258 - AUPR: 0.9336048645218604\n",
      "Epoch:175 Train - Loss: 0.2227679193019867, - AUC: 0.962019964147918 - AUPR: 0.9435621081731961\n",
      "Epoch:176 Train - Loss: 0.26602888107299805, - AUC: 0.9586152379623817 - AUPR: 0.9423578094752707\n",
      "Epoch:177 Train - Loss: 0.23630961775779724, - AUC: 0.9583795867750031 - AUPR: 0.9406821694019011\n",
      "Epoch:178 Train - Loss: 0.26600801944732666, - AUC: 0.9502661715627339 - AUPR: 0.9332716189453445\n",
      "Epoch:179 Train - Loss: 0.26670315861701965, - AUC: 0.9487178880924824 - AUPR: 0.9317061593571728\n",
      "Epoch:180 Train - Loss: 0.25258970260620117, - AUC: 0.9523326512058996 - AUPR: 0.9356505092610111\n",
      "Epoch:181 Train - Loss: 0.24510496854782104, - AUC: 0.9540756030483334 - AUPR: 0.9325793884456268\n",
      "Epoch:182 Train - Loss: 0.23767626285552979, - AUC: 0.9545303546707996 - AUPR: 0.9326985786557637\n",
      "Epoch:183 Train - Loss: 0.2251785695552826, - AUC: 0.9612739980982399 - AUPR: 0.9442033969495035\n",
      "Epoch:184 Train - Loss: 0.22340410947799683, - AUC: 0.9615248208085514 - AUPR: 0.9464161173850376\n",
      "Epoch:185 Train - Loss: 0.22484908998012543, - AUC: 0.9610771623656384 - AUPR: 0.9468977293712018\n",
      "Epoch:186 Train - Loss: 0.22831951081752777, - AUC: 0.9611498674560587 - AUPR: 0.9478423758205446\n",
      "Epoch:187 Train - Loss: 0.22186923027038574, - AUC: 0.9610249486828163 - AUPR: 0.9472704002708513\n",
      "Epoch:188 Train - Loss: 0.2226986438035965, - AUC: 0.9610619908427052 - AUPR: 0.947443257645916\n",
      "Epoch:189 Train - Loss: 0.21972054243087769, - AUC: 0.9626417995554153 - AUPR: 0.9503998043730335\n",
      "Epoch:190 Train - Loss: 0.21611735224723816, - AUC: 0.9632608765041974 - AUPR: 0.95350947993008\n",
      "Epoch:191 Train - Loss: 0.21601970493793488, - AUC: 0.9642373708893547 - AUPR: 0.956060086425243\n",
      "Epoch:192 Train - Loss: 0.2107735276222229, - AUC: 0.9660544070515662 - AUPR: 0.9584629329096156\n",
      "Epoch:193 Train - Loss: 0.2065056562423706, - AUC: 0.9674139331325964 - AUPR: 0.9601351438962736\n",
      "Epoch:194 Train - Loss: 0.2049647867679596, - AUC: 0.9679936035283051 - AUPR: 0.9603056885481429\n",
      "Epoch:195 Train - Loss: 0.20187439024448395, - AUC: 0.9684621474443471 - AUPR: 0.9603639722464395\n",
      "Epoch:196 Train - Loss: 0.2004951685667038, - AUC: 0.9688038022594929 - AUPR: 0.9606621801608958\n",
      "Epoch:197 Train - Loss: 0.20145103335380554, - AUC: 0.9690532457404472 - AUPR: 0.9610748312010774\n",
      "Epoch:198 Train - Loss: 0.19685648381710052, - AUC: 0.9706078342591904 - AUPR: 0.9635194645713456\n",
      "Epoch:199 Train - Loss: 0.19397462904453278, - AUC: 0.9709747092683031 - AUPR: 0.9632238584404333\n",
      "Epoch:200 Train - Loss: 0.19299298524856567, - AUC: 0.970852154888245 - AUPR: 0.9627389075448758\n",
      "[ 0 29]\n",
      "Generated model explanations in ['node_mask', 'edge_mask']\n"
     ]
    }
   ],
   "source": [
    "import scipy.sparse as sp\n",
    "from torch_geometric.explain import Explainer, GNNExplainer, ModelConfig, ThresholdConfig\n",
    "\n",
    "from HGGN import *\n",
    "from utils import *\n",
    "\n",
    "set_seed(10)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "fold = 0\n",
    "hid_r = 128\n",
    "n_layers = 4\n",
    "n_features = 512\n",
    "lr = 0.0005\n",
    "\n",
    "adj, interaction, rna_features, drug_features, inter_features_rna, inter_features_drug, \\\n",
    "    train_pos_data, test_pos_data, train_neg_data, test_neg_data = load_data(data_dir='./data/',\n",
    "                                                                             k_index=fold)\n",
    "\n",
    "global_node_num = int(adj.shape[0] * 0.1)\n",
    "\n",
    "adj = np.vstack((np.hstack((adj, np.ones(shape=(adj.shape[0], global_node_num)))),\n",
    "                 np.hstack((np.ones(shape=(global_node_num, adj.shape[0])),\n",
    "                            np.zeros((global_node_num, global_node_num))))))\n",
    "\n",
    "train_data = np.vstack([train_pos_data, train_neg_data])\n",
    "train_data_label = torch.tensor(\n",
    "    np.vstack([np.ones([train_pos_data.shape[0], 1]), np.zeros([train_neg_data.shape[0], 1])]), dtype=torch.float32)\n",
    "test_data = np.vstack([test_pos_data, test_neg_data])\n",
    "test_data_label = torch.tensor(\n",
    "    np.vstack([np.ones([test_pos_data.shape[0], 1]), np.zeros([test_neg_data.shape[0], 1])]), dtype=torch.float32)\n",
    "\n",
    "sp_adj = sp.coo_matrix(adj)\n",
    "indices = np.vstack((sp_adj.row, sp_adj.col))\n",
    "adj = torch.LongTensor(indices)\n",
    "\n",
    "interaction = torch.tensor(interaction)\n",
    "rna_features = torch.tensor(rna_features)\n",
    "drug_features = torch.tensor(drug_features)\n",
    "inter_features_rna = torch.tensor(inter_features_rna)\n",
    "inter_features_drug = torch.tensor(inter_features_drug)\n",
    "\n",
    "model = HGGN(r=hid_r, n_layers=n_layers, n_features=n_features,\n",
    "             num_rna=rna_features.shape[0],\n",
    "             num_dis=drug_features.shape[0],\n",
    "             n_global_node=global_node_num\n",
    "             )\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "loss_function = torch.nn.BCELoss()\n",
    "\n",
    "for i in range(200):\n",
    "    # train\n",
    "    model.zero_grad()\n",
    "    model.train()\n",
    "    x = model.projection_and_aggregation(rna_features, drug_features, inter_features_rna, inter_features_drug)\n",
    "    train_output = model(x, adj, train_data)\n",
    "    train_loss = loss_function(train_output, train_data_label)\n",
    "    train_auc = metrics.roc_auc_score(train_data_label.detach().cpu().numpy(), train_output.detach().cpu().numpy())\n",
    "    precision, recall, _ = metrics.precision_recall_curve(train_data_label.detach().cpu().numpy(),\n",
    "                                                          train_output.detach().cpu().numpy())\n",
    "    train_aupr = metrics.auc(recall, precision)\n",
    "    print(f'Epoch:{i + 1} Train - Loss: {train_loss.detach().cpu().numpy()}, - AUC: {train_auc} - AUPR: {train_aupr}')\n",
    "    train_loss.backward()\n",
    "    optimizer.step()\n",
    "model.eval()\n",
    "\n",
    "model_config = ModelConfig(\n",
    "    mode='binary_classification',\n",
    "    task_level='edge',\n",
    "    return_type='raw',\n",
    ")\n",
    "\n",
    "explainer = Explainer(\n",
    "    model=model,\n",
    "    explanation_type='phenomenon',\n",
    "    algorithm=GNNExplainer(epochs=100),\n",
    "    node_mask_type='object',\n",
    "    edge_mask_type='object',\n",
    "    model_config=model_config,\n",
    "    threshold_config=ThresholdConfig(threshold_type='topk', value=10)\n",
    ")\n",
    "\n",
    "explanation = explainer(\n",
    "    x=model.projection_and_aggregation(rna_features, drug_features, inter_features_rna,\n",
    "                                       inter_features_drug).detach().cpu(),\n",
    "    edge_index=adj,\n",
    "    coo_data=test_data[0, :].reshape(1, -1),\n",
    "    target=torch.tensor(1)\n",
    ")\n",
    "print(test_data[0, :])\n",
    "print(f'Generated model explanations in {explanation.available_explanations}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "3d1fc62add34d791"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
